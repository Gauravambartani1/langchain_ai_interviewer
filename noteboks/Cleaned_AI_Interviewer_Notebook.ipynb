{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Setup"
      ],
      "metadata": {
        "id": "ds_mw10-JXIZ"
      },
      "id": "ds_mw10-JXIZ"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade langchain google-generativeai pypdf\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Provide your Google API Key\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfhJrV_TJTkR",
        "outputId": "d3327f9f-a0d8-43e5-cfcb-40db59f35237"
      },
      "id": "MfhJrV_TJTkR",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.9.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade langchain google-generativeai langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ0e6ktjJdxG",
        "outputId": "c46aae67-4961-4c6e-d5fc-cccd093d88ce"
      },
      "id": "vQ0e6ktjJdxG",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.0.10)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Using cached langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Using cached langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Using cached langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Using cached langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jXH-XtZnJdtw"
      },
      "id": "jXH-XtZnJdtw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g53vYg0SJdrv"
      },
      "id": "g53vYg0SJdrv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions & Setup"
      ],
      "metadata": {
        "id": "APwSYNFVJeOJ"
      },
      "id": "APwSYNFVJeOJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pypdf import PdfReader\n",
        "\n",
        "def load_document(file_path: str) -> str:\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File not found at {file_path}\")\n",
        "\n",
        "    _, file_extension = os.path.splitext(file_path)\n",
        "    file_extension = file_extension.lower()\n",
        "\n",
        "    text = \"\"\n",
        "    if file_extension == \".txt\":\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "    elif file_extension == \".pdf\":\n",
        "        reader = PdfReader(file_path)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "DUUxjmKqJgrj"
      },
      "id": "DUUxjmKqJgrj",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZlBkDAagJ7Tw"
      },
      "id": "ZlBkDAagJ7Tw",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PGk9TgT9J7Qe"
      },
      "id": "PGk9TgT9J7Qe",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4PFOeTVEJ7Ob"
      },
      "id": "4PFOeTVEJ7Ob",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain Setup"
      ],
      "metadata": {
        "id": "9322BMjlJ7t0"
      },
      "id": "9322BMjlJ7t0"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Instantiate the language model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
        "\n",
        "# Instantiate the memory component\n",
        "memory = ConversationBufferMemory()"
      ],
      "metadata": {
        "id": "JOZvctwtJj_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c829f5-e4f2-4ed9-9d9a-f3ce5a087979"
      },
      "id": "JOZvctwtJj_-",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-959209164.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "You are an expert AI Interviewer for a high-stakes technical interview. Your role is to assess the candidate’s qualifications, skills, and thinking based on the job description and resume.\n",
        "\n",
        "**Strictly follow these rules:**\n",
        "1. Ask *one* clear, concise, and relevant interview question at a time.\n",
        "2. Use the resume to probe deeply into specific experiences or skills the candidate claims.\n",
        "3. Use the job description to test alignment and required competencies.\n",
        "4. Use chat history to:\n",
        "   - Ask meaningful follow-ups.\n",
        "   - Avoid repeating any prior questions or topics.\n",
        "5. Critically evaluate the candidate’s latest response (`Candidate Response`) and:\n",
        "   - Detect generic, evasive, or inconsistent answers.\n",
        "   - Escalate difficulty or ask for clarification if the answer seems suspicious or copied.\n",
        "   - Demand specificity, reasoning, or examples when appropriate.\n",
        "\n",
        "Avoid small talk. Be professional and direct.\n",
        "\n",
        "---\n",
        "\n",
        "**Resume:**\n",
        "{resume}\n",
        "\n",
        "**Job Description:**\n",
        "{job_description}\n",
        "\n",
        "**Conversation So Far:**\n",
        "{chat_history}\n",
        "\n",
        "**Candidate Response:**\n",
        "{human_input}\n",
        "\n",
        "---\n",
        "\n",
        "Based on all the above, ask your next best interview question or follow-up that rigorously tests their skills, depth of knowledge, or experience:\"\"\"\n",
        "\n",
        "interview_prompt = PromptTemplate(\n",
        "    input_variables=[\"resume\", \"job_description\", \"chat_history\", \"human_input\"],\n",
        "    template=template,\n",
        ")\n"
      ],
      "metadata": {
        "id": "4ca2r1QlJo46"
      },
      "id": "4ca2r1QlJo46",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_question(llm, memory, interview_prompt, resume, job_description, human_input):\n",
        "    \"\"\"\n",
        "    Generates the next interview question using the language model and prompt template.\n",
        "\n",
        "    Args:\n",
        "        llm: The language model instance.\n",
        "        memory: The conversation memory object.\n",
        "        interview_prompt: The prompt template object.\n",
        "        resume: The resume text.\n",
        "        job_description: The job description text.\n",
        "        human_input: The candidate's current response.\n",
        "\n",
        "    Returns:\n",
        "        The generated interview question (AI's response).\n",
        "    \"\"\"\n",
        "    # Get chat history from memory\n",
        "    chat_history = memory.buffer\n",
        "\n",
        "    # Format the prompt\n",
        "    formatted_prompt = interview_prompt.format(\n",
        "        resume=resume,\n",
        "        job_description=job_description,\n",
        "        chat_history=chat_history,\n",
        "        human_input=human_input\n",
        "    )\n",
        "\n",
        "    # Invoke the language model\n",
        "    response = llm.invoke(formatted_prompt)\n",
        "\n",
        "    # Return the generated question\n",
        "    return response.content\n"
      ],
      "metadata": {
        "id": "ai-49omBJ9_A"
      },
      "id": "ai-49omBJ9_A",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Runs the main interview loop.\n",
        "    \"\"\"\n",
        "    resume_path = \"resume.txt\"\n",
        "    jd_path = \"job_description.txt\"\n",
        "\n",
        "    try:\n",
        "        resume_text = load_document(resume_path)\n",
        "        jd_text = load_document(jd_path)\n",
        "        print(\"Files loaded successfully.\")\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        print(f\"Error loading files: {e}\")\n",
        "        return\n",
        "\n",
        "    # Components are already initialized in previous steps: llm, memory, interview_prompt\n",
        "\n",
        "    question_counter = 0\n",
        "\n",
        "    print(\"\\nStarting interview. Type 'quit' or 'exit' to end.\")\n",
        "\n",
        "    human_input = \"\" # Initial empty input for the first question\n",
        "\n",
        "    while True and question_counter < 3:\n",
        "        # Generate the next question\n",
        "        ai_question = generate_question(llm, memory, interview_prompt, resume_text, jd_text, human_input)\n",
        "\n",
        "        # Print the AI's question\n",
        "        print(f\"\\nAI Interviewer: {ai_question}\")\n",
        "\n",
        "        # Get candidate's response\n",
        "        human_input = input(\"Your response: \")\n",
        "\n",
        "        # Check for exit command\n",
        "        if human_input.lower() in [\"quit\", \"exit\"]:\n",
        "            print(\"Ending interview.\")\n",
        "            # Save conversation history before breaking\n",
        "            history_file = \"interview_history.txt\"\n",
        "            with open(history_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                # Access the chat history from memory\n",
        "                chat_history = memory.buffer\n",
        "                f.write(chat_history)\n",
        "            print(f\"Conversation history saved to {history_file}\")\n",
        "            break\n",
        "\n",
        "        # Save context to memory\n",
        "        # The generate_question function already takes the latest human_input,\n",
        "        # so we save the AI's question and the human's response to memory *after*\n",
        "        # the question has been generated using the previous turn's human_input.\n",
        "        # This ensures the memory for the *next* turn includes the current turn's interaction.\n",
        "        memory.save_context({\"ai\": ai_question} , {\"human\": human_input})\n",
        "        question_counter = question_counter + 1\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create dummy files for testing if they don't exist\n",
        "    if not os.path.exists(\"resume.txt\"):\n",
        "        with open(\"resume.txt\", \"w\") as f:\n",
        "            f.write(\"Resume content: Experienced software engineer with skills in Python and data analysis.\")\n",
        "    if not os.path.exists(\"jd.txt\"):\n",
        "        with open(\"jd.txt\", \"w\") as f:\n",
        "            f.write(\"Job Description content: Seeking a software engineer with experience in Python, machine learning, and cloud computing.\")\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sy71Q0FKfJb",
        "outputId": "c89837a3-1686-43d9-ba47-d2af490265f9"
      },
      "id": "3sy71Q0FKfJb",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files loaded successfully.\n",
            "\n",
            "Starting interview. Type 'quit' or 'exit' to end.\n",
            "\n",
            "AI Interviewer: Your resume highlights your work at Technopurple IT Solutions, where you \"implemented a machine learning-based system that significantly enhanced ETA accuracy by 30% through regression and time series analysis.\" Given the Associate Data Scientist role's focus on energy load forecasting using time series techniques, can you describe the specific time series models or algorithms you employed for ETA prediction, and how you evaluated their performance and selected the best approach?\n",
            "Your response: I have used LSTM, please hire me\n",
            "\n",
            "AI Interviewer: You mentioned using LSTM for ETA prediction. Can you elaborate on how you specifically structured the input data and designed the LSTM architecture for this task? Furthermore, what specific metrics did you use to evaluate the LSTM's performance, and how did it compare to other regression or time series models you considered or implemented for that project?\n",
            "Your response: no nigga i cant\n",
            "\n",
            "AI Interviewer: Given your latest response, this interview cannot continue.\n",
            "Your response: quit\n",
            "Ending interview.\n",
            "Conversation history saved to interview_history.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DaBU5ncqK0p-"
      },
      "id": "DaBU5ncqK0p-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4i6l1ZfN4pN"
      },
      "id": "q4i6l1ZfN4pN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E8-toLdKM1Nh"
      },
      "id": "E8-toLdKM1Nh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ycHX0t2oM1KA"
      },
      "id": "ycHX0t2oM1KA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSAwLBaCM1Hu"
      },
      "id": "CSAwLBaCM1Hu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CwX0RiyqNuR7"
      },
      "id": "CwX0RiyqNuR7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCYZy-HCNuPK"
      },
      "id": "fCYZy-HCNuPK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarizing & Scoring"
      ],
      "metadata": {
        "id": "PgZd_omhM1dk"
      },
      "id": "PgZd_omhM1dk"
    },
    {
      "cell_type": "code",
      "source": [
        "history_path = 'interview_history.txt'\n",
        "history_text = load_document(history_path)\n",
        "print(\"Succesfully Loaded Interview History\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn3c7I9MM4yL",
        "outputId": "72d87c93-c0ff-4aaf-f293-d8011b08fc29"
      },
      "id": "Zn3c7I9MM4yL",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfully Loaded Interview History\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import re # Import regex module for extracting the score\n",
        "\n",
        "def calculate_score(llm, resume_text: str, jd_text: str, conversation_history: str) -> tuple[int | None, str]:\n",
        "    \"\"\"\n",
        "    Calculates a numerical score (on a scale of 1-10) and a qualitative assessment\n",
        "    of the candidate's performance based on the resume, job description, and\n",
        "    conversation history using an LLM.\n",
        "\n",
        "    Args:\n",
        "        llm: The language model instance.\n",
        "        resume_text: The resume text.\n",
        "        jd_text: The job description text.\n",
        "        conversation_history: The complete conversation history as a string.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "            - An integer score from 1 to 10, or None if a score cannot be extracted.\n",
        "            - A string containing the qualitative assessment of the candidate.\n",
        "    \"\"\"\n",
        "    scoring_template = \"\"\"You are an AI evaluating a candidate's interview performance.\n",
        "Given the resume, job description, and the full interview conversation history,\n",
        "provide a qualitative assessment of the candidate's suitability for the role.\n",
        "Consider the following:\n",
        "- How well the candidate's skills and experience align with the job requirements.\n",
        "- The relevance and depth of the candidate's answers.\n",
        "- How effectively the candidate addressed the interviewer's questions.\n",
        "- Overall communication clarity and confidence.\n",
        "\n",
        "Provide a brief summary of their strengths and weaknesses based on the interview,\n",
        "and a concluding assessment of their fit for the position.\n",
        "Additionally, provide a numerical score from 1 to 10 (where 1 is poor and 10 is excellent)\n",
        "at the very beginning of your response, formatted as \"SCORE: [number]/10\".\n",
        "\n",
        "Resume:\n",
        "{resume}\n",
        "\n",
        "Job Description:\n",
        "{job_description}\n",
        "\n",
        "Conversation History:\n",
        "{history}\n",
        "\n",
        "Candidate Assessment:\n",
        "\"\"\"\n",
        "\n",
        "    scoring_prompt = PromptTemplate(\n",
        "        input_variables=[\"resume\", \"job_description\", \"history\"],\n",
        "        template=scoring_template,\n",
        "    )\n",
        "\n",
        "    # Create a simple chain to format the prompt and invoke the LLM\n",
        "    chain = (\n",
        "        {\"resume\": RunnablePassthrough(), \"job_description\": RunnablePassthrough(), \"history\": RunnablePassthrough()}\n",
        "        | scoring_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "\n",
        "    # Invoke the chain with the necessary inputs\n",
        "    full_assessment_text = chain.invoke({\n",
        "        \"resume\": resume_text,\n",
        "        \"job_description\": jd_text,\n",
        "        \"history\": conversation_history\n",
        "    })\n",
        "\n",
        "    # Extract the score using regex\n",
        "    score_match = re.search(r\"SCORE:\\s*(\\d+)/10\", full_assessment_text)\n",
        "    score = int(score_match.group(1)) if score_match else None\n",
        "\n",
        "    # The assessment text is the full response minus the score line if found\n",
        "    assessment_text = full_assessment_text\n",
        "    if score_match:\n",
        "        assessment_text = re.sub(r\"SCORE:\\s*\\d+/10\\s*\", \"\", full_assessment_text, 1).strip()\n",
        "\n",
        "\n",
        "    return score, assessment_text\n",
        "\n",
        "# Re-initialize llm and memory (as they might have been lost in between cell executions)\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
        "memory = ConversationBufferMemory() # Memory is not directly used in calculate_score, but good practice to have it initialized if needed later\n",
        "\n",
        "# Load the resume, job description, and conversation history\n",
        "resume_path = \"resume.txt\"\n",
        "jd_path = \"job_description.txt\"\n",
        "history_file_path = \"interview_history.txt\"\n",
        "\n",
        "try:\n",
        "    resume_text = load_document(resume_path)\n",
        "    jd_text = load_document(jd_path)\n",
        "    conversation_history = load_document(history_file_path)\n",
        "    print(\"Required files and history loaded successfully.\")\n",
        "\n",
        "    # Now call the calculate_score function and print both the score and the assessment\n",
        "    print(\"\\n--- Generating Candidate Assessment ---\")\n",
        "    candidate_score, candidate_assessment = calculate_score(llm, resume_text, jd_text, conversation_history)\n",
        "\n",
        "    if candidate_score is not None:\n",
        "        print(f\"\\nOverall Score: {candidate_score}/10\")\n",
        "    else:\n",
        "        print(\"\\nCould not extract a numerical score.\")\n",
        "\n",
        "    print(\"\\n--- Candidate Assessment ---\")\n",
        "    print(candidate_assessment)\n",
        "\n",
        "except (FileNotFoundError, ValueError) as e:\n",
        "    print(f\"Error loading files or history: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwHeoWmLNB3i",
        "outputId": "8d599c8e-cf78-4902-f9b0-d9a041fae911"
      },
      "id": "SwHeoWmLNB3i",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required files and history loaded successfully.\n",
            "\n",
            "--- Generating Candidate Assessment ---\n",
            "\n",
            "Overall Score: 1/10\n",
            "\n",
            "--- Candidate Assessment ---\n",
            "**Qualitative Assessment of Candidate's Suitability for the Role**\n",
            "\n",
            "The candidate's suitability for the Associate Data Scientist role is extremely poor, primarily due to their interview performance. While the resume presents a strong technical background and relevant experience, the interview conversation completely undermines any potential fit.\n",
            "\n",
            "**How well the candidate's skills and experience align with the job requirements:**\n",
            "Based solely on the resume, there appears to be a good alignment. The candidate has experience with time series analysis, regression, Python, relevant libraries (PyTorch, TensorFlow, scikit-learn), SQL, and cloud platforms (AWS, Azure), all of which are directly listed in the job description. The \"ETA accuracy\" project specifically mentions time series analysis and regression, which is highly relevant to energy load forecasting. However, the interview completely failed to demonstrate this alignment or the depth of the candidate's understanding.\n",
            "\n",
            "**The relevance and depth of the candidate's answers:**\n",
            "The answers provided were entirely lacking in relevance and depth.\n",
            "*   In response to the first question about specific time series models, evaluation, and selection, the candidate merely stated, \"I have used LSTM, please hire me.\" This is a superficial answer that fails to address the core technical aspects of the question (how it was evaluated, how the best approach was selected).\n",
            "*   The second response, \"no nigga i cant,\" is not only completely devoid of depth but also highly unprofessional and offensive. It demonstrates an absolute refusal to engage with the technical details of their claimed experience.\n",
            "\n",
            "**How effectively the candidate addressed the interviewer's questions:**\n",
            "The candidate was completely ineffective in addressing the interviewer's questions. They either provided a minimal, uninformative statement or outright refused to answer in an extremely inappropriate manner. There was no attempt to elaborate, clarify, or demonstrate their understanding of the subject matter.\n",
            "\n",
            "**Overall communication clarity and confidence:**\n",
            "Communication clarity was minimal, and what little was communicated was unprofessional. The candidate showed a complete lack of professional communication skills. Their responses indicated either a severe lack of technical understanding regarding the details of their projects, an extreme lack of professionalism, or both. The confidence, if any, manifested as arrogance or dismissiveness rather than a positive, collaborative trait.\n",
            "\n",
            "**Strengths (based on the interview):**\n",
            "None. The interview performance revealed no discernible strengths. The candidate's behavior and responses were entirely detrimental.\n",
            "\n",
            "**Weaknesses (based on the interview):**\n",
            "*   **Severe Lack of Professionalism:** The use of offensive and disrespectful language (\"no nigga i cant\") is an immediate and absolute disqualifier. This demonstrates a complete disregard for professional conduct and the interview process.\n",
            "*   **Poor Communication Skills:** The candidate failed to articulate technical details, explain their past work, or engage in a meaningful conversation. Responses were curt, uninformative, and inappropriate.\n",
            "*   **Inability to Elaborate on Technical Experience:** Despite having relevant projects on their resume, the candidate could not or would not provide any detail on the methodology, architecture, or evaluation of models they claimed to have implemented. This casts serious doubt on the depth of their actual technical knowledge.\n",
            "*   **Lack of Engagement and Respect:** The candidate showed no interest in answering the questions or demonstrating their capabilities, instead resorting to unprofessional behavior.\n",
            "\n",
            "**Concluding Assessment of Fit for the Position:**\n",
            "The candidate is entirely unsuitable for the Associate Data Scientist position. While the resume suggests a promising technical profile with relevant skills and project experience, their interview performance was unacceptable. The extreme lack of professionalism, use of offensive language, and complete inability to answer fundamental technical questions about their own projects make them an immediate and definitive rejection for any professional role.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJ1nGgZ2N1V8"
      },
      "id": "YJ1nGgZ2N1V8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}